from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import os
import json
import asyncio
import logging
import sys
from io import StringIO

from browser_use import Agent, ChatOpenAI
from browser_use.browser import BrowserProfile

app = FastAPI(title="Browser Agent Service")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class TaskRequest(BaseModel):
    task: str
    wp_url: str
    wp_user: str
    wp_pass: str
    openai_api_key: str

class LogCapture(logging.Handler):
    """Custom handler Ï€Î¿Ï… capture Ï„Î± logs Ï„Î¿Ï… browser_use"""
    def __init__(self, queue):
        super().__init__()
        self.queue = queue
        
    def emit(self, record):
        try:
            msg = self.format(record)
            self.queue.put_nowait({
                'level': record.levelname,
                'message': msg,
                'module': record.module
            })
        except:
            pass

async def stream_agent_logs(request: TaskRequest):
    """Generator Î¼Îµ detailed streaming logs"""
    try:
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± queue Î³Î¹Î± logs
        log_queue = asyncio.Queue()
        
        # Setup custom logger Î³Î¹Î± browser_use
        browser_logger = logging.getLogger('browser_use')
        browser_logger.setLevel(logging.INFO)
        
        # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· custom handler
        handler = LogCapture(log_queue)
        handler.setFormatter(logging.Formatter('%(message)s'))
        browser_logger.addHandler(handler)
        
        # Î‘ÏÏ‡Î¹ÎºÎ¬ Î¼Î·Î½ÏÎ¼Î±Ï„Î±
        yield f"data: {json.dumps({'type': 'info', 'message': 'ğŸš€ Î•ÎºÎºÎ¯Î½Î·ÏƒÎ· AI Agent Pro...', 'step': 0})}\n\n"
        await asyncio.sleep(0.3)
        
        yield f"data: {json.dumps({'type': 'info', 'message': f'ğŸŒ Target: {request.wp_url}', 'step': 0})}\n\n"
        await asyncio.sleep(0.3)
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± LLM
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            api_key=request.openai_api_key
        )
        
        full_task = f"""
WordPress URL: {request.wp_url}
Username: {request.wp_user}
Password: {request.wp_pass}

Î•Î¡Î“Î‘Î£Î™Î‘: {request.task}

Î’Î—ÎœÎ‘Î¤Î‘:
1. Î Î®Î³Î±Î¹Î½Îµ ÏƒÏ„Î¿ {request.wp_url}/wp-admin
2. Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ Username: {request.wp_user}
3. Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ Password: {request.wp_pass}
4. Î Î¬Ï„Î± "Î£ÏÎ½Î´ÎµÏƒÎ·" Î® "Log In"
5. Î•ÎºÏ„Î­Î»ÎµÏƒÎµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± Î²Î®Î¼Î±-Î²Î®Î¼Î± Î¼Îµ Ï€ÏÎ¿ÏƒÎ¿Ï‡Î®
6. Î£Ï„Î¿ Ï„Î­Î»Î¿Ï‚ Î³ÏÎ¬ÏˆÎµ Î‘ÎÎ‘Î›Î¥Î¤Î™ÎšÎ‘ Ï„Î¹ Î­ÎºÎ±Î½ÎµÏ‚
"""
        
        yield f"data: {json.dumps({'type': 'system', 'message': 'ğŸ¤– Initializing AI Brain...', 'step': 0})}\n\n"
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± agent
        agent = Agent(
            task=full_task,
            llm=llm,
            use_vision=True,
            browser_profile=BrowserProfile(
                headless=True,
                slow_mo=500,
                timeout=60000,
                wait_until="networkidle",
                disable_security=False
            )
        )
        
        yield f"data: {json.dumps({'type': 'system', 'message': 'ğŸ”¥ Launching Chrome Browser...', 'step': 0})}\n\n"
        await asyncio.sleep(0.3)
        
        # Task Î³Î¹Î± ÎµÎºÏ„Î­Î»ÎµÏƒÎ· agent
        async def run_agent():
            return await agent.run()
        
        # Task Î³Î¹Î± monitoring logs
        async def monitor_logs():
            step_counter = 0
            while True:
                try:
                    log_entry = await asyncio.wait_for(log_queue.get(), timeout=0.1)
                    
                    msg = log_entry['message']
                    
                    # Parse Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ types
                    if 'ğŸ“ Step' in msg:
                        step_counter += 1
                        step_num = msg.split('Step')[1].split(':')[0].strip()
                        yield f"data: {json.dumps({'type': 'step', 'message': f'ğŸ“ Step {step_num}', 'step': step_counter})}\n\n"
                    
                    elif 'ğŸ‘ Eval:' in msg:
                        eval_text = msg.split('Eval:')[1].strip()
                        yield f"data: {json.dumps({'type': 'eval', 'message': f'ğŸ‘ {eval_text}', 'step': step_counter})}\n\n"
                    
                    elif 'ğŸ§  Memory:' in msg:
                        memory_text = msg.split('Memory:')[1].strip()
                        yield f"data: {json.dumps({'type': 'memory', 'message': f'ğŸ§  {memory_text}', 'step': step_counter})}\n\n"
                    
                    elif 'ğŸ¯ Next goal:' in msg:
                        goal_text = msg.split('Next goal:')[1].strip()
                        yield f"data: {json.dumps({'type': 'goal', 'message': f'ğŸ¯ {goal_text}', 'step': step_counter})}\n\n"
                    
                    elif 'â–¶ï¸' in msg:
                        action_text = msg.split('â–¶ï¸')[1].strip()
                        yield f"data: {json.dumps({'type': 'action', 'message': f'â–¶ï¸ {action_text}', 'step': step_counter})}\n\n"
                    
                    elif 'ğŸ–±ï¸' in msg or 'click' in msg.lower():
                        yield f"data: {json.dumps({'type': 'action', 'message': f'ğŸ–±ï¸ {msg}', 'step': step_counter})}\n\n"
                    
                    elif 'âŒ¨ï¸' in msg or 'type' in msg.lower():
                        yield f"data: {json.dumps({'type': 'action', 'message': f'âŒ¨ï¸ {msg}', 'step': step_counter})}\n\n"
                    
                    elif 'ğŸ§­' in msg or 'navigate' in msg.lower():
                        yield f"data: {json.dumps({'type': 'action', 'message': f'ğŸ§­ {msg}', 'step': step_counter})}\n\n"
                    
                    elif 'ERROR' in log_entry['level']:
                        yield f"data: {json.dumps({'type': 'error', 'message': f'âŒ {msg}', 'step': step_counter})}\n\n"
                    
                    else:
                        # Generic info
                        yield f"data: {json.dumps({'type': 'info', 'message': msg, 'step': step_counter})}\n\n"
                    
                    await asyncio.sleep(0.05)
                    
                except asyncio.TimeoutError:
                    await asyncio.sleep(0.1)
                    continue
                except Exception as e:
                    break
        
        # Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Ï€Î±ÏÎ¬Î»Î»Î·Î»Î±
        agent_task = asyncio.create_task(run_agent())
        
        # Stream logs
        async for log_data in monitor_logs():
            yield log_data
            
            # Check Î±Î½ Ï„ÎµÎ»ÎµÎ¯Ï‰ÏƒÎµ Ï„Î¿ agent
            if agent_task.done():
                break
        
        # Î ÎµÏÎ¯Î¼ÎµÎ½Îµ Î½Î± Ï„ÎµÎ»ÎµÎ¹ÏÏƒÎµÎ¹
        result = await agent_task
        
        # Cleanup
        browser_logger.removeHandler(handler)
        
        # Î¤ÎµÎ»Î¹ÎºÏŒ Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î±
        yield f"data: {json.dumps({'type': 'success', 'message': 'âœ… Task Completed Successfully!', 'step': 999})}\n\n"
        await asyncio.sleep(0.3)
        
        # Parse result
        output = ""
        if hasattr(result, 'final_result'):
            output = str(result.final_result())
        elif hasattr(result, 'history') and result.history:
            output = "\n".join([str(h) for h in result.history[-5:]])
        else:
            output = str(result)
        
        # Î£Ï„ÎµÎ¯Î»Îµ summary
        yield f"data: {json.dumps({'type': 'result', 'message': 'ğŸ“‹ SUMMARY', 'step': 999})}\n\n"
        
        for line in output.split('\n')[:15]:
            if line.strip():
                yield f"data: {json.dumps({'type': 'result', 'message': line.strip(), 'step': 999})}\n\n"
                await asyncio.sleep(0.1)
        
        yield f"data: {json.dumps({'type': 'done', 'message': 'ğŸ‰ All Done!', 'step': 999})}\n\n"
        
    except Exception as e:
        import traceback
        error_msg = f"{type(e).__name__}: {str(e)}"
        yield f"data: {json.dumps({'type': 'error', 'message': f'âŒ Fatal Error: {error_msg}', 'step': 0})}\n\n"
        
        tb = traceback.format_exc()
        for line in tb.split('\n')[:8]:
            if line.strip():
                yield f"data: {json.dumps({'type': 'error', 'message': line, 'step': 0})}\n\n"

@app.post("/execute-stream")
async def execute_task_stream(request: TaskRequest):
    """Streaming endpoint Î¼Îµ detailed logs"""
    return StreamingResponse(
        stream_agent_logs(request),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

@app.post("/execute")
async def execute_task(request: TaskRequest):
    """Regular endpoint (Î³Î¹Î± backward compatibility)"""
    try:
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            api_key=request.openai_api_key
        )

        full_task = f"""
WordPress URL: {request.wp_url}
Username: {request.wp_user}
Password: {request.wp_pass}

Î•Î¡Î“Î‘Î£Î™Î‘: {request.task}

Î’Î—ÎœÎ‘Î¤Î‘:
1. Î Î®Î³Î±Î¹Î½Îµ ÏƒÏ„Î¿ {request.wp_url}/wp-admin
2. Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ Username: {request.wp_user}
3. Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ Password: {request.wp_pass}
4. Î Î¬Ï„Î± "Î£ÏÎ½Î´ÎµÏƒÎ·" Î® "Log In"
5. Î•ÎºÏ„Î­Î»ÎµÏƒÎµ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¯Î± Î²Î®Î¼Î±-Î²Î®Î¼Î±
6. Î£Ï„Î¿ Ï„Î­Î»Î¿Ï‚ Î³ÏÎ¬ÏˆÎµ Î‘ÎÎ‘Î›Î¥Î¤Î™ÎšÎ‘ Ï„Î¹ Î­ÎºÎ±Î½ÎµÏ‚
"""

        agent = Agent(
            task=full_task,
            llm=llm,
            use_vision=True,
            browser_profile=BrowserProfile(
                headless=True,
                slow_mo=500,
                timeout=60000,
                wait_until="networkidle",
                disable_security=False
            )
        )

        result = await agent.run()
        
        output = ""
        if hasattr(result, 'final_result'):
            output = str(result.final_result())
        elif hasattr(result, 'history') and result.history:
            output = "\n\n".join([str(h) for h in result.history[-5:]])
        else:
            output = str(result)
        
        return {
            "success": True, 
            "result": output,
            "model_used": "gpt-4o-mini"
        }

    except Exception as e:
        import traceback
        return {
            "success": False, 
            "error": f"{type(e).__name__}: {str(e)}",
            "traceback": traceback.format_exc()
        }

@app.get("/health")
def health():
    return {
        "status": "ok",
        "message": "Browser Agent Pro LIVE!",
        "version": "3.0.0 - Enhanced Logging"
    }

@app.get("/")
def root():
    return {
        "name": "Browser Agent Pro API",
        "endpoints": {
            "POST /execute": "Run task (regular)",
            "POST /execute-stream": "Run task (streaming with detailed logs)",
            "GET /health": "Health check"
        }
    }

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)

